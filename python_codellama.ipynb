{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "import os\n",
    "# 设置代理。这里 1080 既可以是 http 代理的端口，也可以是 socks5 代理的端口\n",
    "proxy = 'https://mobisense.tns:m0b1sensevpn@g2-jp4.go2https.com:20006'\n",
    "os.environ['http_proxy'] = proxy\n",
    "os.environ['HTTP_PROXY'] = proxy\n",
    "os.environ['https_proxy'] = proxy\n",
    "os.environ['HTTPS_PROXY'] = proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'vision_models.BLIPModel'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388d40598bec47e2bfedec72413b45b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'vision_models.DepthEstimationModel'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
      "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'vision_models.GLIPModel'>\n",
      "VISION BACKBONE USE GRADIENT CHECKPOINTING:  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c45c5301d7347ef8fb4d60d64b391da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1460d64fe4174300a96d865ef94854c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/334 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade38e8e702f46bcb5bfeff9e31cb053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f72cd0f4464f12896d30c49a184a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d053735b984d4ed1902c11d066739442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n",
      "EARLY FUSION ON, USING MHA-B\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCONFIG_NAMES\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython_codellama\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmain_simple_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m im \u001b[38;5;241m=\u001b[39m load_image(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://viper.cs.columbia.edu/static/images/kids_muffins.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHow many muffins can each kid have for it to be fair?\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Repos/viper/main_simple_lib.py:32\u001b[0m\n\u001b[1;32m     29\u001b[0m cache \u001b[38;5;241m=\u001b[39m Memory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcache/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     31\u001b[0m mp\u001b[38;5;241m.\u001b[39mset_start_method(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvision_processes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward, finish_all_consumers  \u001b[38;5;66;03m# This import loads all the models. May take a while\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimage_patch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvideo_segment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Repos/viper/vision_processes.py:180\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m process_name_ \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mload_models \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mload_models[process_name_]:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28mprint\u001b[39m(model_class_)\n\u001b[0;32m--> 180\u001b[0m             consumers[process_name_] \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_class_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_name_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounter_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m             counter_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    183\u001b[0m queues_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/viper/vision_processes.py:45\u001b[0m, in \u001b[0;36mmake_fn\u001b[0;34m(model_class, process_name, counter)\u001b[0m\n\u001b[1;32m     42\u001b[0m num_gpus \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m     43\u001b[0m gpu_number \u001b[38;5;241m=\u001b[39m counter \u001b[38;5;241m%\u001b[39m num_gpus\n\u001b[0;32m---> 45\u001b[0m model_instance \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu_number\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m process_name \u001b[38;5;241m!=\u001b[39m model_class\u001b[38;5;241m.\u001b[39mname:\n",
      "File \u001b[0;32m~/Repos/viper/vision_models.py:606\u001b[0m, in \u001b[0;36mGLIPModel.__init__\u001b[0;34m(self, model_size, gpu_number, *args)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m bboxes, inference_output\u001b[38;5;241m.\u001b[39mget_field(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m bboxes\n\u001b[0;32m--> 606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglip_demo \u001b[38;5;241m=\u001b[39m \u001b[43mOurGLIPDemo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdev\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/viper/vision_models.py:461\u001b[0m, in \u001b[0;36mGLIPModel.__init__.<locals>.OurGLIPDemo.__init__\u001b[0;34m(self, dev, *args_demo)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m    460\u001b[0m     logging\u001b[38;5;241m.\u001b[39mset_verbosity_error()\n\u001b[0;32m--> 461\u001b[0m     \u001b[43mGLIPDemo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_demo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mRPN_ARCHITECTURE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVLDYHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    463\u001b[0m     plus \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Repos/viper/GLIP/maskrcnn_benchmark/engine/predictor_glip.py:50\u001b[0m, in \u001b[0;36mGLIPDemo.__init__\u001b[0;34m(self, cfg, confidence_threshold, min_image_size, show_mask_heatmaps, masks_per_dim, load_model, tensor_inputs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_model:\n\u001b[1;32m     49\u001b[0m     checkpointer \u001b[38;5;241m=\u001b[39m DetectronCheckpointer(cfg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, save_dir\u001b[38;5;241m=\u001b[39msave_dir)\n\u001b[0;32m---> 50\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWEIGHT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor_inputs:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_tensor_transforms()\n",
      "File \u001b[0;32m~/Repos/viper/GLIP/maskrcnn_benchmark/utils/checkpoint.py:72\u001b[0m, in \u001b[0;36mCheckpointer.load\u001b[0;34m(self, f, force, keyword, skip_optimizer)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f))\n\u001b[0;32m---> 72\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(checkpoint, keyword\u001b[38;5;241m=\u001b[39mkeyword)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# if resume training, load optimizer and scheduler,\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# otherwise use the specified LR in config yaml for fine-tuning\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/viper/GLIP/maskrcnn_benchmark/utils/checkpoint.py:160\u001b[0m, in \u001b[0;36mDetectronCheckpointer._load_file\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_pretrain_format(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg, f)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# load native detectron.pytorch checkpoint\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDetectronCheckpointer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded:\n\u001b[1;32m    162\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m=\u001b[39mloaded)\n",
      "File \u001b[0;32m~/Repos/viper/GLIP/maskrcnn_benchmark/utils/checkpoint.py:115\u001b[0m, in \u001b[0;36mCheckpointer._load_file\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, f):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vipergpt/lib/python3.10/site-packages/torch/serialization.py:1097\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1105\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/vipergpt/lib/python3.10/site-packages/torch/serialization.py:1525\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# Needed for tensors where storage device and rebuild tensor device are\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1525\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location\n\u001b[1;32m   1528\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/miniconda3/envs/vipergpt/lib/python3.10/site-packages/torch/serialization.py:1492\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1491\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1492\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/vipergpt/lib/python3.10/site-packages/torch/serialization.py:1457\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset:storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CONFIG_NAMES'] = 'python_codellama'\n",
    "\n",
    "from main_simple_lib import *\n",
    "im = load_image('https://viper.cs.columbia.edu/static/images/kids_muffins.jpg')\n",
    "query = 'How many muffins can each kid have for it to be fair?'\n",
    "\n",
    "show_single_image(im)\n",
    "code = get_code(query)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vipergpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
